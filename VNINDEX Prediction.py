# -*- coding: utf-8 -*-
"""NHÓM 9_BIG DATA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M5o2I5kFOMfu5w-P_Q_2vLMhiaTxR1l6
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""***EDA***"""

df = pd.read_excel('DATA_FULL.xlsx')
print(df.shape)
df.head(20)

df.describe()

#tổng số các giá trị null trong các biến
print(df.isnull().sum())

#xác định các biến số có giá trị null
missing_values = df.isnull().sum()
missing_values = missing_values[missing_values > 0]
print(missing_values)

#Biểu đồ thể hiện số lượng giá trị null của các biến có giá trị null
plt.figure(figsize =(8,6))
missing_values.plot(kind ='bar', color ='red')
for i, v in enumerate(missing_values):
    plt.text (i,v, str(v), ha = 'center', va = 'bottom', color = 'red')
    plt.xticks(rotation = 360)
    plt.xlabel ('Biến')
    plt.ylabel ('Số lượng biến null trong mỗi biến')
    plt.savefig('Số lượng biến null trong mỗi biến', dpi = 300)

df =df.dropna()
df.head(20)

from scipy.stats import zscore
import matplotlib.pyplot as plt

# Tính z-score cho các cột số
z_scores = df[['VNINDEX_y', 'Dow Jones', 'Tỷ giá hối đoái', 'Lãi suất', 'Giá dầu thô', 'Giá vàng thế giới']].apply(zscore)

# Xác định các hàng có giá trị ngoại lai (z-score lớn hơn 3 hoặc nhỏ hơn -3)
outliers = (z_scores.abs() > 3).any(axis=1)

# Vẽ scatter plot cho từng cặp biến đặc trưng và đánh dấu ngoại lai
for feature in ['Dow Jones', 'Tỷ giá hối đoái', 'Lãi suất', 'Giá dầu thô', 'Giá vàng thế giới']:
    plt.figure(figsize=(12, 8))  # Tạo figure mới cho mỗi biểu đồ
    plt.scatter(df[feature], df['VNINDEX_y'], label='Data Points', alpha=0.5)
    plt.scatter(df[feature][outliers], df['VNINDEX_y'][outliers], color='red', label='Outliers', alpha=0.7)
    plt.xlabel(feature)
    plt.ylabel('VNINDEX_y')
    plt.title(f'Outliers in {feature} vs VNINDEX_y')
    plt.legend()
    plt.savefig(f'Outliers_{feature}_vs_VNINDEX_y.png', dpi=300)  # Lưu từng biểu đồ với tên riêng

# drop các giá trị ngoại lai
df = df[~outliers].reset_index(drop=True)
df.head(20)

# Set Seaborn style
sns.set_style("darkgrid")

# Identify numerical columns
numerical_columns = df.select_dtypes(include=["int64", "float64"]).columns

# Plot distribution of each numerical feature
plt.figure(figsize=(14, len(numerical_columns) * 3))
for idx, feature in enumerate(numerical_columns, 1):
    plt.subplot(len(numerical_columns), 2, idx)
    sns.histplot(df[feature], kde=True)
    plt.title(f"{feature} | Skewness: {round(df[feature].skew(), 2)}")

# Adjust layout and show plots
plt.tight_layout()
plt.savefig('Biểu đồ Mật độ Kernel')

# 2. Kiểm tra mối tương quan giữa các biến với ma trận tương quan
df = df.drop(columns=['Thời gian'])
correlation_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Ma trận Tương Quan giữa các Biến")
plt.savefig('Ma trận tương quan', dpi = 300)

from scipy.stats import pearsonr, spearmanr
# Kiểm tra mối tương quan chi tiết với từng biến độc lập và biến phụ thuộc
print("\nMối tương quan chi tiết với VNINDEX:")
for col in df.columns:
    if col != 'VNINDEX_y':
        pearson_corr, _ = pearsonr(df['VNINDEX_y'], df[col])
        spearman_corr, _ = spearmanr(df['VNINDEX_y'], df[col])
        print(f"{col} - Pearson: {pearson_corr:.2f}, Spearman: {spearman_corr:.2f}")

# Phân tích xu hướng theo thời gian
plt.figure(figsize=(15, 8))
plt.plot(df['VNINDEX_y'], label='VNINDEX')
plt.plot(df['Dow Jones'], label='Dow Jones', linestyle='--')
plt.plot(df['Tỷ giá hối đoái'], label='Tỷ giá hối đoái', linestyle='--')
plt.plot(df['Lãi suất'], label='Lãi suất', linestyle='--')
plt.plot(df['Giá dầu thô'], label='Giá dầu thô', linestyle='--')
plt.plot(df['Giá vàng thế giới'], label='Giá vàng thế giới', linestyle='--')
plt.legend()
plt.title("Xu hướng theo thời gian của VNINDEX và các biến số kinh tế")
plt.savefig('xu hướng theo tgian', dpi = 300)

import pandas as pd
import numpy as np
#!pip install statsmodels
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.api import VAR
#!pip install scikit-learn
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression

# Tạo lag features (độ trễ)
def create_lag_features(dfn, lag=1):
    for col in ['VNINDEX_y', 'Dow Jones', 'Tỷ giá hối đoái', 'Lãi suất', 'Giá dầu thô', 'Giá vàng thế giới']:
        dfn[f"{col}_lag{lag}"] = dfn[col].shift(lag)
    return dfn

# Tạo các lag features (1 ngày trễ và 2 ngày trễ)
dflags = create_lag_features(df.copy(), lag=1)
dflags = create_lag_features(dflags, lag=2)

# Loại bỏ các giá trị NaN sinh ra do tạo lag features
dfn = dflags.dropna()

X = dfn.iloc[:, 7:]
X.head(20)

y = dfn['VNINDEX_y']
y.head(20)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 17, test_size = 0.2, shuffle = False)

from sklearn.metrics import mean_absolute_error, mean_squared_error

"""***ARIMA & SARIMA***"""

# Xây dựng mô hình 1a: ARIMA
#ARIMA
#!pip install statsmodels
from statsmodels.tsa.arima.model import ARIMA
def arima_model(y_train, y_test):
    model = ARIMA(y_train, order=(5,1,0))
    model_fit = model.fit()
    y_pred1a = model_fit.forecast(steps=len(y_test))
    return y_pred1a
# Huyến luyện + dự đoán mô hình
y_pred_arima = arima_model(y_train, y_test)
mse_arima = mean_squared_error(y_test, y_pred_arima)
mae_arima = mean_absolute_error(y_test, y_pred_arima)
print(f"ARIMA MSE: {mse_arima:.2f}")
print(f"ARIMA MAE: {mae_arima:.2f}")

# Xây dựng mô hình 1b: Seasonal ARIMA
#Seasonal ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
def seasonal_arima_model(y_train, y_test):
    model = SARIMAX(y_train, order=(5,1,0), seasonal_order=(1,1,1,12))
    results = model.fit(disp=False)
    y_pred1b = results.predict(start=len(y_train), end=len(y_train)+len(y_test)-1, dynamic=False)
    return y_pred1b
# Huấn luyện + dự đoán mô hình
y_pred_arima_s = seasonal_arima_model(y_train, y_test)
mse_arima_s = mean_squared_error(y_test, y_pred_arima_s)
mae_arima_s = mean_absolute_error(y_test, y_pred_arima_s)
print(f"Seasonal ARIMA MSE: {mse_arima_s:.2f}")
print(f"Seasonal ARIMA MAE: {mae_arima_s:.2f}")

# Model tốt hơn giữa hai model này
best_model_1 = min(
    [('ARIMA', mse_arima, mae_arima),
     ('Seasonal ARIMA', mse_arima_s, mae_arima_s)],
    key=lambda x: x[1]
)
print(f"Model tốt hơn là: {best_model_1[0]} với MSE là: {best_model_1[1]} và MAE là: {best_model_1[2]}")

"""***RANDOM FOREST & QUANTILE RANDOM FOREST***"""

# Xây dựng mô hình 2a: Random Forest
from sklearn.ensemble import RandomForestRegressor
def random_forest_model(X_train, y_train, X_test):
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    y_pred2a = model.predict(X_test)
    return y_pred2a
y_pred_rf = random_forest_model(X_train, y_train, X_test)
mse_rf = mean_squared_error(y_test, y_pred_rf)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
print(f"Random Forest MSE: {mse_rf:.2f}")
print(f"Random Forest MAE: {mae_rf:.2f}")

!pip install quantile-forest
# Xây dựng mô hình 2b: Random Forest Quantile Regression
from quantile_forest import RandomForestQuantileRegressor
# Hàm xây dựng mô hình và dự đoán
def quantile_random_forest_model(X_train, y_train, X_test):
    model = RandomForestQuantileRegressor(n_estimators=200, random_state=42, max_depth=10)
    model.fit(X_train, y_train)
    y_pred2b = model.predict(X_test, quantiles=[0.025, 0.5, 0.975])
    return y_pred2b

# Dự đoán
y_pred_qrf = quantile_random_forest_model(X_train, y_train, X_test)

# Lấy giá trị trung vị (quantile 0.5)
y_pred_median = y_pred_qrf[:, 1]

# Đánh giá mô hình
mse_qrf = mean_squared_error(y_test[:len(y_pred_median)], y_pred_median)
mae_qrf = mean_absolute_error(y_test[:len(y_pred_median)], y_pred_median)

print(f"Quantile Random Forest MSE: {mse_qrf:.2f}")
print(f"Quantile Random Forest MAE: {mae_qrf:.2f}")

# Chọn model tốt nhất giữa hai model
best_model_2 = min(
    [('RANDOM FOREST', mse_rf, mae_rf),
     ('Quantile Random Forest', mse_qrf, mae_qrf)],
    key=lambda x: x[1]
)
print(f"Model tốt hơn là: {best_model_2[0]} với MSE là: {best_model_2[1]} và MAE là: {best_model_2[2]}")

"""***XGBOOST & LIGHT GBM***"""

# Xây dựng mô hình 3: XG Boost
#!pip install xgboost
import xgboost as xgb
def xgboost_model(X_train, y_train, X_test):
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test)
    params = {"objective": "reg:squarederror", "max_depth": 5, "eta": 0.1}
    model = xgb.train(params, dtrain, num_boost_round=100)
    y_pred3a = model.predict(dtest)
    return y_pred3a
y_pred_xgb = xgboost_model(X_train, y_train, X_test)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
print(f"XGBoost MSE: {mse_xgb:.2f}")
print(f"XGBoost MAE: {mae_xgb:.2f}")

#!pip install lightgbm
import lightgbm as lgb
def lightgbm_model(X_train, y_train, X):
    dtrain = lgb.Dataset(X_train, label=y_train)
    dtest = lgb.Dataset(X_test, label=y_test, reference=dtrain)
    params = {
    "objective": "regression",     # Đặt mục tiêu là hồi quy
    "boosting_type": "gbdt",         # Sử dụng Gradient Boosting
    "num_leaves": 5,
    "force_row_wise": True,
    "learning_rate": 0.5,
    "metric": ["mse", "mae"],      # Bao gồm cả mse và mae
    "bagging_fraction": 0.8,
    "feature_fraction": 0.8
}
    model = lgb.train(params, dtrain, num_boost_round=500, valid_sets=[dtest])
    y_pred3b = model.predict(X)
    return y_pred3b
y_pred_lgbm = lightgbm_model(X_train, y_train, X_test)
mse_lgbm = mean_squared_error(y_test, y_pred_lgbm)
mae_lgbm = mean_absolute_error(y_test, y_pred_lgbm)
print(f"LightGBM MSE: {mse_lgbm:.2f}")
print(f"LightGBM MAE: {mae_lgbm:.2f}")

# Chọn model thích hợp trong cả hai model
best_model_3 = min(
    [('XGBoost', mse_xgb, mae_xgb),
     ('LightGBM', mse_lgbm, mae_lgbm)],
    key=lambda x: x[1]
)
print(f"Model tốt hơn là: {best_model_3[0]} với MSE là: {best_model_3[1]} và MAE là: {best_model_3[2]}")

"""***ANN & DNN***"""

import numpy as np
import sklearn.metrics
import tensorflow as tf
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)
X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.2, shuffle=True)
# Xây dưng mô hình ANN
ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units=4, activation='relu'))
ann.add(tf.keras.layers.Dense(units=6, activation='relu'))
ann.add(tf.keras.layers.Dense(units=1))
ann.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['MeanSquaredLogarithmicError'])
# train
model = ann.fit(X_train, y_train, batch_size = 32, epochs = 25,validation_data=(X_val, y_val), shuffle=True)
y_pred5a = ann.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred5a.reshape(len(y_pred5a), 1), y_test.to_numpy().reshape(len(y_test), 1)), axis=1))
mse_ann=sklearn.metrics.mean_squared_error(y_test,ann.predict(X_test))
mae_ann=sklearn.metrics.mean_absolute_error(y_test,ann.predict(X_test))
print(f"ANN MSE: {mse_ann:.2f}")
print(f"ANN MAE: {mae_ann:.2f}")

import numpy as np
import sklearn.metrics
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Conv2D
from tensorflow.keras.layers import Flatten, MaxPooling2D
from sklearn.model_selection import train_test_split
# Chia dữ liệu thành tập huấn luyện, tập kiểm tra, và tập validation
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)
# Xây dựng mô hình DNN
dnn = Sequential()
dnn.add(tf.keras.layers.Dense(units=4, activation='relu'))
dnn.add(tf.keras.layers.Dense(units=6, activation='relu'))
dnn.add(tf.keras.layers.Dense(units=1))  # Không có activation cho đầu ra liên tục
dnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])
# Huấn luyện mô hình
model = dnn.fit(X_train, y_train, batch_size=32, epochs=25, validation_data=(X_val, y_val), shuffle=True)
# Dự đoán trên tập kiểm tra
y_pred5b = dnn.predict(X_test)
# Hiển thị kết quả dự đoán và giá trị thực
np.set_printoptions(precision=2)
print(np.concatenate((y_pred5b.reshape(len(y_pred5b), 1), y_test.to_numpy().reshape(len(y_test), 1)), axis=1))
# Tính toán MSE và MAE cho tập kiểm tra
mse_dnn = sklearn.metrics.mean_squared_error(y_test, y_pred5b)
mae_dnn = sklearn.metrics.mean_absolute_error(y_test, y_pred5b)
print(f"DNN MSE: {mse_dnn:.2f}")
print(f"DNN MAE: {mae_dnn:.2f}")

# Chọn model tốt nhất trong hai model
best_model_5 = min(
    [('ANN', mse_ann, mae_ann),
     ('DNN', mse_dnn, mae_dnn)],
    key=lambda x: x[1]
)
print(f"Model tốt hơn là: {best_model_5[0]} với MSE là: {best_model_5[1]} và MAE là: {best_model_5[2]}")

"""***MSE & MAE***"""

# Tổng hợp MSE và MAE của 5 phương pháp: ARIMA, Random Forest, XGBoost, Linear Regression, ANN
print(f"ARIMA MSE: {mse_arima:.2f} và ARIMA MAE: {mae_arima:.2f}")
print(f"RANDOM FOREST MSE: {mse_rf:.2f} và RANDOM FOREST MAE: {mae_rf:.2f}")
print(f"XGBoost MSE: {mse_xgb:.2f} và XGBoost MAE: {mae_xgb:.2f}")
print(f"ANN MSE: {mse_ann:.2f} và ANN MAE: {mae_ann:.2f}")

# 8. Chọn model có MSE và MAE nhỏ nhất
best_model = min(
    [('ARIMA', mse_arima, mae_arima),
     ('RANDOM FOREST', mse_rf, mae_rf),
     ('XGBoost', mse_xgb, mae_xgb),
     ('ANN', mse_ann, mae_ann)],
    key=lambda x: x[1]
)
print(f"Chọn model: {best_model[0]} có MSE: {best_model[1]}, MAE: {best_model[2]}")

"""***FORECAST***"""

# Xây dựng mô hình Random Forest Regression
def random_forest_model(X_train, y_train, X_test):
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    y_pred2a = model.predict(X_test)
    return model, y_pred2a

# Huấn luyện và dự đoán
model, y_pred_rf = random_forest_model(X_train, y_train, X_test)

# Lấy giá trị trung bình (mean prediction)
y_pred_median = y_pred_rf

# Đánh giá mô hình
valid_indices = ~pd.isna(y_test)  # Không cần kiểm tra y_pred_median vì Random Forest không trả về NaN
y_test_valid = y_test[valid_indices]
y_pred_median_valid = y_pred_median[valid_indices]

# Dự báo VNINDEX_y cho 7 ngày tiếp theo
X_last_week = X.tail(7)  # Sử dụng các đặc trưng hiện tại từ dữ liệu
if X_last_week.isna().any().any():
    print("Dữ liệu đầu vào cho dự báo tuần tới chứa giá trị NaN. Vui lòng kiểm tra dữ liệu!")
else:
    # Bootstrap Sampling để tính dải không chắc chắn
    n_bootstrap = 100  # Số lần bootstrap sampling
    bootstrap_predictions = []

    # Vòng lặp bootstrap
    for i in range(n_bootstrap):
        # Bootstrap resampling
        indices = np.random.choice(len(X_train), size=len(X_train), replace=True)

        # Sử dụng iloc để lấy mẫu lại từ DataFrame hoặc Series
        X_resampled = X_train.iloc[indices] if isinstance(X_train, pd.DataFrame) else X_train[indices]
        y_resampled = y_train.iloc[indices] if isinstance(y_train, pd.Series) else y_train[indices]

        # Train a new Random Forest model on the resampled data
        bootstrap_model = RandomForestRegressor(n_estimators=100, random_state=i)
        bootstrap_model.fit(X_resampled, y_resampled)

        # Predict on the last week's data
        bootstrap_predictions.append(bootstrap_model.predict(X_last_week))

    # Convert bootstrap predictions to NumPy array
    bootstrap_predictions = np.array(bootstrap_predictions)

    # Tính giá trị trung bình và dải không chắc chắn
    future_predictions_mean = bootstrap_predictions.mean(axis=0)
    future_predictions_low = np.percentile(bootstrap_predictions, 2.5, axis=0)
    future_predictions_high = np.percentile(bootstrap_predictions, 97.5, axis=0)

    # Tạo DataFrame để hiển thị kết quả dự báo
    predicted_week = pd.DataFrame({
        'Ngày': pd.date_range(start=df['Thời gian'].iloc[-1] + pd.Timedelta(days=1), periods=7, freq='D'),
        'Dự báo VNINDEX_y (Trung bình)': future_predictions_mean,
        'Dải thấp (2.5%)': future_predictions_low,
        'Dải cao (97.5%)': future_predictions_high
    })


# Hiển thị kết quả
plt.figure(figsize=(14, 8))

# Giá trị thực
plt.plot(df['Thời gian'][-len(y_test):], y_test, label='Giá trị thực', color='blue', linewidth=2, linestyle='-', alpha=0.8)

# Dự báo trung bình
plt.plot(df['Thời gian'][-len(y_pred_median):], y_pred_median, label='Dự báo (Trung bình)', color='green', linewidth=2.5, linestyle='--')

# Dải không chắc chắn
plt.fill_between(
    predicted_week['Ngày'],
    predicted_week['Dải thấp (2.5%)'],
    predicted_week['Dải cao (97.5%)'],
    color='orange', alpha=0.3, label='Dải dự báo tuần tới (2.5%-97.5%)'
)

# Dự báo cho 7 ngày tiếp theo
plt.plot(predicted_week['Ngày'], predicted_week['Dự báo VNINDEX_y (Trung bình)'], label='Dự báo tuần tới (Trung bình)', color='orange', marker='o', linestyle='-')

# Tùy chỉnh biểu đồ
plt.title("Kết quả dự báo VNINDEX_y (Random Forest)", fontsize=18, fontweight='bold', color='darkblue')
plt.xlabel("Thời gian", fontsize=14, fontweight='bold')
plt.ylabel("VNINDEX_y", fontsize=14, fontweight='bold')
plt.xticks(fontsize=12, rotation=45)
plt.yticks(fontsize=12)
plt.legend(fontsize=12, loc='upper left', frameon=True, shadow=True)
plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.7)

# Lưu biểu đồ
plt.savefig('forecast_vnindex_combined.png', dpi=300, bbox_inches='tight')
plt.show()

# Hiển thị bảng kết quả
print("\nDự báo VNINDEX_y cho 7 ngày tiếp theo:")
print(predicted_week)

# Biểu đồ dự báo VNINDEX_y trong 7 ngày tới
plt.figure(figsize=(10, 6))

# Dự báo trung bình
plt.plot(predicted_week['Ngày'], predicted_week['Dự báo VNINDEX_y (Trung bình)'],
         label='Dự báo trung bình', color='orange', marker='o', linestyle='-')

# Dải không chắc chắn
plt.fill_between(
    predicted_week['Ngày'],
    predicted_week['Dải thấp (2.5%)'],
    predicted_week['Dải cao (97.5%)'],
    color='orange', alpha=0.3, label='Dải dự báo (2.5%-97.5%)'
)

# Tùy chỉnh biểu đồ
plt.title("Dự báo VNINDEX_y trong 7 ngày tới", fontsize=16, fontweight='bold', color='darkblue')
plt.xlabel("Thời gian", fontsize=14)
plt.ylabel("VNINDEX_y", fontsize=14)
plt.xticks(fontsize=12, rotation=45)
plt.yticks(fontsize=12)
plt.legend(fontsize=12, loc='upper left', frameon=True, shadow=True)
plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.7)

# Hiển thị biểu đồ
plt.tight_layout()
plt.show()